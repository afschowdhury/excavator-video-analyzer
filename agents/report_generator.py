"""Report generation agent using GPT-5"""

import os
from typing import Any, Dict, List, Optional
from openai import OpenAI
from dotenv import load_dotenv

from .base_agent import BaseAgent

from icecream import ic
ic.configureOutput(includeContext=True, prefix="ReportGenerator- ")


class ReportGeneratorAgent(BaseAgent):
    """Agent responsible for generating markdown reports from cycle data"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__("ReportGenerator", config)
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")

        self.client = OpenAI(api_key=api_key)
        self.model = self.config.get("model", "gpt-4o")
        self.temperature = self.config.get("temperature", 0.3)

    def process(
        self, input_data: List[Dict[str, Any]], context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Generate markdown report from cycle data

        Args:
            input_data: List of cycles from CycleAssemblerAgent
            context: Optional context with video metadata

        Returns:
            Markdown formatted report
        """
        self.log(f"Generating report for {len(input_data)} cycles", "info")
        self.log("Creating cycle table and analysis...", "info")

        # Create cycle table
        cycle_table = self._create_cycle_table(input_data)

        # Get video metadata from context
        video_info = ""
        if context:
            duration = context.get("video_duration", 0)
            total_frames = context.get("total_frames", 0)
            fps = context.get("fps", 0)
            video_info = f"\n**Video Duration:** {duration:.1f}s | **Frames Analyzed:** {total_frames} | **Sample Rate:** {fps} FPS\n"

        # Create detailed analysis using GPT-5
        detailed_analysis = self._generate_analysis(input_data, context)

        # Assemble report
        report = f"""## Cycle Time Analysis Report

{video_info}

### Excavation Cycles

{cycle_table}

### Analysis

{detailed_analysis}

---
*Report generated by GPT-5 Multi-Agent Video Analyzer*
"""

        self.log("âœ“ Report generated successfully", "success")
        return report

    def _create_cycle_table(self, cycles: List[Dict[str, Any]]) -> str:
        """
        Create markdown table of cycles

        Args:
            cycles: List of cycle dictionaries

        Returns:
            Markdown formatted table
        """
        if not cycles:
            return "*No complete cycles detected in the video.*"

        table = "| Cycle # | Start Time | End Time | Duration | Notes |\n"
        table += "|---------|------------|----------|----------|-------|\n"

        for cycle in cycles:
            cycle_num = cycle["cycle_number"]
            start = cycle["start_time_str"]
            end = cycle["end_time_str"]
            duration = cycle["duration_str"]
            notes = cycle["observations"]

            table += f"| {cycle_num} | {start} | {end} | {duration} | {notes} |\n"

        return table

    def _generate_analysis(
        self, cycles: List[Dict[str, Any]], context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Generate detailed analysis using GPT-5

        Args:
            cycles: List of cycle dictionaries
            context: Optional context

        Returns:
            Analysis text
        """
        if not cycles:
            return "No cycles were detected in the video. The excavator may not have completed any full excavation cycles during the recorded period."

        # Prepare data summary for GPT-5
        cycle_summary = []
        for cycle in cycles:
            cycle_summary.append(
                {
                    "cycle": cycle["cycle_number"],
                    "duration": cycle["duration"],
                    "phases": cycle.get("phases", {}),
                    "complete": cycle["is_complete"],
                }
            )

        # Calculate statistics
        total_cycles = len(cycles)
        complete_cycles = sum(1 for c in cycles if c["is_complete"])
        avg_duration = sum(c["duration"] for c in cycles) / total_cycles
        min_duration = min(c["duration"] for c in cycles)
        max_duration = max(c["duration"] for c in cycles)

        prompt = f"""Analyze the following excavation cycle data and provide insights:

**Statistics:**
- Total cycles: {total_cycles}
- Complete cycles: {complete_cycles}
- Average duration: {avg_duration:.1f}s
- Fastest cycle: {min_duration:.1f}s
- Slowest cycle: {max_duration:.1f}s

**Cycle Data:**
{cycle_summary}

Provide a brief analysis (2-3 paragraphs) covering:
1. Overall performance and efficiency
2. Notable patterns or variations
3. Suggestions for improvement if any

Be concise and focus on actionable insights."""

        try:
            # Determine which token parameter to use based on model
            # GPT-5 models use max_completion_tokens, GPT-4 models use max_tokens
            token_params = {}
            if self.model.startswith("gpt-5"):
                token_params["max_completion_tokens"] = 500
            else:
                token_params["max_tokens"] = 500

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert excavator operations analyst. Provide clear, concise analysis of excavation cycle data.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=self.temperature,
                **token_params
            )
            ic(prompt)
            ic(response)

            return response.choices[0].message.content.strip()

        except Exception as e:
            self.log(f"Failed to generate detailed analysis: {e}", "warning")
            # Fallback to basic analysis
            return self._generate_basic_analysis(
                total_cycles, complete_cycles, avg_duration, min_duration, max_duration
            )

    def _generate_basic_analysis(
        self,
        total_cycles: int,
        complete_cycles: int,
        avg_duration: float,
        min_duration: float,
        max_duration: float,
    ) -> str:
        """
        Generate basic analysis without GPT-5

        Args:
            total_cycles: Total number of cycles
            complete_cycles: Number of complete cycles
            avg_duration: Average cycle duration
            min_duration: Minimum cycle duration
            max_duration: Maximum cycle duration

        Returns:
            Basic analysis text
        """
        analysis = f"""**Performance Summary:**

The video captured {total_cycles} excavation cycle{'s' if total_cycles != 1 else ''}, with {complete_cycles} complete cycle{'s' if complete_cycles != 1 else ''}. """

        analysis += f"The average cycle time was {avg_duration:.1f} seconds, ranging from {min_duration:.1f}s (fastest) to {max_duration:.1f}s (slowest). "

        # Add performance comment
        if avg_duration < 15:
            analysis += "The cycles show efficient operation with relatively quick turnaround times. "
        elif avg_duration > 25:
            analysis += "The cycle times suggest opportunities for optimization to improve efficiency. "

        # Add consistency comment
        variation = max_duration - min_duration
        if variation < 5:
            analysis += "Cycle times are consistent, indicating stable operation."
        else:
            analysis += (
                f"There is notable variation ({variation:.1f}s) between cycles, which may warrant investigation."
            )

        return analysis

